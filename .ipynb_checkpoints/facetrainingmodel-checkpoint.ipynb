{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45735a09-26bc-4ffb-bc2e-f10813a57bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-preprocessing in c:\\users\\madhu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\madhu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-preprocessing) (2.0.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\madhu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-preprocessing) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-preprocessing\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6cfbd2-20bc-4bf2-bf4d-2734724ecbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d7ef7-b1ff-4e44-b0e0-a3c47ffed0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c75e7f-0261-4133-9b2a-22b50a975c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56147605-5ed9-4203-a6c1-5498e1d9a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d07c02-16a8-48b0-bbb6-73e20518569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc7fa0-4be3-4b8f-ab8a-088c9be7e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd462c2-edad-46df-97b5-9e59ab26c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db638926-4daa-4bd5-aa2b-4f64d6f53e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39d44f-532c-4921-abb2-7b6134db7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00f8a6-cb0e-4079-b80c-afd6a24a8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981d095-8705-44b3-ad97-7ff694ad52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1323d-ce2a-4ad5-895b-88506bd7a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f820481-779b-45e7-b56c-6a35acb783d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb382b-c2c0-4844-8db5-20c14a4a4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccfe9c-4282-47c6-8b21-5eb5680a4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f2d14-595f-4f8d-9f58-ebddf624cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e00ab3-2681-44d8-9a73-e127ffcbd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d20f67-995b-449c-965a-ac47740e4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c23c64-2f0c-456c-bc9b-1515462098bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f458a-7882-4351-890c-dc527e2a2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c2fb8-91b9-4b0c-9c71-fb2b3caa7937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ce943-116e-4c78-a149-10eec450aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161557d-2208-461e-bc5e-805985a2be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8576a-bc95-4100-ac94-960cf74d15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/sad/Training_2913.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963ed27-f98b-49d5-a494-dd918015ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f71b92-0d1c-4975-8761-c91ca4d54231",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/sad/Training_2913.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762da238-4ff6-4bd5-97f9-3680ceb0fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/fear/Training_12567.jpg'\n",
    "print(\"original image is of fear\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738e7cc-fe7c-4e5b-9dd7-34c31e48376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/disgust/Training_659019.jpg'\n",
    "print(\"original image is of disgust\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404061ce-e2b5-4e0c-980d-f071100e2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/happy/Training_1206.jpg'\n",
    "print(\"original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315abdf-16e7-49bd-97a6-9188065e17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/surprise/Training_8796.jpg'\n",
    "print(\"original image is of surprise\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941ec55-9bc5-4531-b37f-88fea1c00489",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/angry/Training_3908.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d1294-4f30-47c2-a6e1-8c764f880403",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/neutral/Training_65667.jpg'\n",
    "print(\"original image is of neutral\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6c375-eada-4436-8f1b-22a3012f911d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4d940-73e5-42e1-a91e-306146b670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "json_file_path = \"emotiondetector.json\"\n",
    "weights_file_path = \"emotiondetector.h5\"\n",
    "\n",
    "# Verify JSON file\n",
    "if not os.path.exists(json_file_path) or not os.path.getsize(json_file_path):\n",
    "    raise FileNotFoundError(f\"JSON file is missing or empty: {json_file_path}\")\n",
    "\n",
    "# Verify weights file\n",
    "if not os.path.exists(weights_file_path):\n",
    "    raise FileNotFoundError(f\"Weights file is missing: {weights_file_path}\")\n",
    "\n",
    "# Load the model architecture\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "\n",
    "# Initialize model\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load weights\n",
    "model.load_weights(weights_file_path)\n",
    "\n",
    "# Load Haar cascade\n",
    "haar_file = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "def extract_features(image):\n",
    "    feature = np.array(image)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0\n",
    "\n",
    "# Webcam setup\n",
    "webcam = cv2.VideoCapture(0)\n",
    "labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "\n",
    "# Real-time detection loop\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = webcam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray[y:y + h, x:x + w]\n",
    "            face_resized = cv2.resize(face, (48, 48))\n",
    "            features = extract_features(face_resized)\n",
    "            prediction = model.predict(features)\n",
    "            emotion = labels[prediction.argmax()]\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "finally:\n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284a696-bd40-4b08-b6fb-2e7f323e5725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f32d7d-28dc-4e82-bd3b-0a1bff24b765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b280b0-a6e0-4a19-be3b-ab5dd11f061e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885143fd-ef97-4818-b06e-2a33aacec26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9117d-bfb7-42df-8ffe-6e08619145ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869a005-029f-49fa-99ff-934a95b39353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f6ab3-391a-4a3c-bc10-c4f2aeedea38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9501135-1dae-4ce4-bcfa-0db585d2fa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52add9-0da8-4186-9ea4-8d013da5359a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0243fc-2105-4f21-b5cf-2557ff917bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
